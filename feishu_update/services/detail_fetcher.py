"""
äº§å“è¯¦æƒ…æŠ“å–æœåŠ¡
"""

import json
import subprocess
import tempfile
import os
import time
from typing import Dict, Optional, List
from pathlib import Path


class DetailFetcher:
    """äº§å“è¯¦æƒ…æŠ“å–å™¨

    è´Ÿè´£è°ƒç”¨Node.jsè„šæœ¬æŠ“å–äº§å“è¯¦æƒ…æ•°æ®ï¼Œå¹¶è§£æè¿”å›ç»“æœã€‚
    """

    def __init__(self, project_root: Optional[str] = None) -> None:
        """åˆå§‹åŒ–æŠ“å–å™¨

        Args:
            project_root: é¡¹ç›®æ ¹ç›®å½•è·¯å¾„ï¼Œé»˜è®¤è‡ªåŠ¨æŸ¥æ‰¾
        """
        self.project_root = project_root or self._find_project_root()
        self.scrape_script = os.path.join(self.project_root, 'scripts', 'scrape_product_detail.js')
        self.last_fetch_time = 0
        self.fetch_interval = float(os.getenv('DETAIL_FETCH_INTERVAL', '2.0'))  # é»˜è®¤2ç§’é—´éš”
        
    def _find_project_root(self) -> str:
        """è‡ªåŠ¨æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
        current_dir = Path(__file__).parent
        while current_dir != current_dir.parent:
            if (current_dir / 'scripts' / 'scrape_product_detail.js').exists():
                return str(current_dir)
            current_dir = current_dir.parent
        
        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œä½¿ç”¨ç›¸å¯¹è·¯å¾„
        return os.getcwd()
    
    def needs_detail_fetch(self, product: Dict) -> bool:
        """æ£€æŸ¥äº§å“æ˜¯å¦éœ€è¦æŠ“å–è¯¦æƒ…

        æ£€æŸ¥æ˜¯å¦ç¼ºå°‘é¢œè‰²ã€å°ºç ã€å›¾ç‰‡ç­‰å…³é”®ä¿¡æ¯ã€‚

        Args:
            product: äº§å“æ•°æ®å­—å…¸

        Returns:
            bool: å¦‚æœéœ€è¦æŠ“å–è¯¦æƒ…åˆ™è¿”å›True
        """
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦å·²ç»æœ‰è¯¦æƒ…æ•°æ®
        if product.get('_detail_data') or product.get('extra', {}).get('_detail_data'):
            return False

        # æ£€æŸ¥æ˜¯å¦ç¼ºå°‘å…³é”®å­—æ®µ
        colors = product.get('colors', [])
        sizes = product.get('sizes', [])
        images = product.get('imagesMetadata', [])

        # å¦‚æœé¢œè‰²ã€å°ºç ã€å›¾ç‰‡ä»»ä¸€ä¸ºç©ºï¼Œåˆ™éœ€è¦æŠ“å–
        return not colors or not sizes or not images
    
    def fetch_product_detail(self, product_url: str, product_id: str = None) -> Optional[Dict]:
        """æŠ“å–å•ä¸ªäº§å“çš„è¯¦æƒ…æ•°æ®

        Args:
            product_url: äº§å“è¯¦æƒ…é¡µURL
            product_id: äº§å“IDï¼ˆå¯é€‰ï¼Œä»URLè‡ªåŠ¨æå–ï¼‰

        Returns:
            Dict: æŠ“å–çš„è¯¦æƒ…æ•°æ®ï¼Œå¦‚æœå¤±è´¥åˆ™è¿”å›None
        """
        # é™é€Ÿï¼šç¡®ä¿è¯·æ±‚é—´éš”
        current_time = time.time()
        time_since_last = current_time - self.last_fetch_time
        if time_since_last < self.fetch_interval:
            sleep_time = self.fetch_interval - time_since_last
            print(f"â³ é™é€Ÿä¸­ï¼Œç­‰å¾… {sleep_time:.1f} ç§’...")
            time.sleep(sleep_time)

        try:
            print(f"ğŸ” æ­£åœ¨æŠ“å–äº§å“è¯¦æƒ…: {product_id or 'unknown'}")
            self.last_fetch_time = time.time()
            
            # åˆ›å»ºä¸´æ—¶è¾“å‡ºç›®å½•
            with tempfile.TemporaryDirectory() as temp_dir:
                # æ„å»ºå‘½ä»¤å‚æ•°
                cmd = [
                    'node', self.scrape_script,
                    '--url', product_url,
                    '--output-dir', temp_dir
                ]
                
                if product_id:
                    cmd.extend(['--product-id', product_id])
                
                # æ‰§è¡Œnodeè„šæœ¬
                result = subprocess.run(
                    cmd,
                    capture_output=True,
                    text=True,
                    timeout=180,  # 3åˆ†é’Ÿè¶…æ—¶
                    cwd=self.project_root
                )
                
                if result.returncode != 0:
                    print(f"âŒ æŠ“å–å¤±è´¥: {result.stderr}")
                    return None
                
                # æŸ¥æ‰¾ç”Ÿæˆçš„JSONæ–‡ä»¶
                json_files = list(Path(temp_dir).glob(f'product_details_{product_id}_*.json'))
                if not json_files:
                    json_files = list(Path(temp_dir).glob('product_details_*.json'))
                
                if not json_files:
                    print(f"âŒ æœªæ‰¾åˆ°è¾“å‡ºæ–‡ä»¶")
                    return None
                
                # è¯»å–æœ€æ–°çš„JSONæ–‡ä»¶
                latest_file = sorted(json_files)[-1]
                with open(latest_file, 'r', encoding='utf-8') as f:
                    detail_data = json.load(f)
                
                print(f"âœ… æŠ“å–æˆåŠŸ: {detail_data['scrapeInfo']['totalImages']}å¼ å›¾ç‰‡, {detail_data['scrapeInfo']['totalColors']}ç§é¢œè‰², {detail_data['scrapeInfo']['totalSizes']}ä¸ªå°ºç ")
                return detail_data
                
        except subprocess.TimeoutExpired:
            print(f"âŒ æŠ“å–è¶…æ—¶: {product_url}")
            return None
        except Exception as e:
            print(f"âŒ æŠ“å–å¼‚å¸¸: {e}")
            return None
    
    def merge_detail_into_product(self, product: Dict, detail_data: Dict) -> Dict:
        """å°†è¯¦æƒ…æ•°æ®åˆå¹¶åˆ°äº§å“æ•°æ®ä¸­

        Args:
            product: åŸå§‹äº§å“æ•°æ®
            detail_data: æŠ“å–çš„è¯¦æƒ…æ•°æ®

        Returns:
            Dict: åˆå¹¶åçš„äº§å“æ•°æ®
        """
        # åˆ›å»ºäº§å“å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
        enhanced_product = product.copy()

        # å…³é”®ï¼šå°†å®Œæ•´çš„è¯¦æƒ…æ•°æ®å­˜å‚¨åˆ° _detail_data å­—æ®µ
        enhanced_product['_detail_data'] = detail_data

        # åˆå¹¶é¢œè‰²ä¿¡æ¯
        if detail_data.get('colors'):
            enhanced_product['colors'] = [
                color.get('name', color.get('code', 'Unknown'))
                for color in detail_data['colors']
            ]

        # åˆå¹¶å°ºç ä¿¡æ¯
        if detail_data.get('sizes'):
            enhanced_product['sizes'] = detail_data['sizes']

        # åˆå¹¶å›¾ç‰‡ä¿¡æ¯
        if detail_data.get('images', {}).get('product'):
            # æ„å»ºå›¾ç‰‡å…ƒæ•°æ®æ ¼å¼
            images_metadata = []
            colors = detail_data.get('colors', [])
            images_data = detail_data['images']
            
            # ä¼˜å…ˆä½¿ç”¨variantsä¸­çš„é¢œè‰²-å›¾ç‰‡å¯¹åº”å…³ç³»
            if images_data.get('variants') and colors:
                # æŒ‰é¢œè‰²åˆ†ç»„å¤„ç†å›¾ç‰‡
                for color in colors:
                    color_code = color.get('code', '')
                    color_name = color.get('name', '')
                    
                    # æŸ¥æ‰¾è¯¥é¢œè‰²å¯¹åº”çš„å›¾ç‰‡
                    color_images = images_data['variants'].get(color_code, [])
                    
                    # å¦‚æœè¯¥é¢œè‰²æ²¡æœ‰ä¸“å±å›¾ç‰‡ï¼Œä½¿ç”¨productä¸­çš„å›¾ç‰‡
                    if not color_images and images_data.get('product'):
                        color_images = images_data['product']
                    
                    # ä¸ºè¯¥é¢œè‰²çš„æ¯å¼ å›¾ç‰‡åˆ›å»ºå…ƒæ•°æ®
                    for i, image_url in enumerate(color_images):
                        images_metadata.append({
                            'name': f'{color_name}_{i+1}' if color_name else f'Image_{len(images_metadata)+1}',
                            'url': image_url,
                            'colorName': color_name,
                            'colorCode': color_code
                        })
                        
            enhanced_product['imagesMetadata'] = images_metadata
        
        # æ·»åŠ è¯¦æƒ…æ•°æ®å¼•ç”¨ï¼ˆç”¨äºFieldAssemblerï¼‰
        enhanced_product['_detail_data'] = detail_data

        # ä¿ç•™å°ºç è¡¨æ–‡æœ¬ï¼Œä¾¿äºåç»­æ ¼å¼åŒ–
        if detail_data.get('sizeSectionText'):
            enhanced_product['sizeSectionText'] = detail_data.get('sizeSectionText')
        if detail_data.get('sizeSection', {}).get('text'):
            enhanced_product['sizeSectionText'] = detail_data['sizeSection']['text']
        
        return enhanced_product
    
    def fetch_and_enhance_products(self, products: List[Dict]) -> List[Dict]:
        """æ‰¹é‡æŠ“å–å¹¶å¢å¼ºäº§å“æ•°æ®
        
        Args:
            products: äº§å“åˆ—è¡¨
            
        Returns:
            List[Dict]: å¢å¼ºåçš„äº§å“åˆ—è¡¨
        """
        enhanced_products = []
        
        for product in products:
            try:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ“å–è¯¦æƒ…
                if not self.needs_detail_fetch(product):
                    print(f"â­ï¸ äº§å“ {product.get('productId', 'unknown')} æ— éœ€æŠ“å–è¯¦æƒ…")
                    enhanced_products.append(product)
                    continue
                
                # è·å–äº§å“URLå’ŒID
                product_url = product.get('detailUrl') or product.get('detail_url')
                product_id = product.get('productId') or product.get('product_id')
                
                if not product_url:
                    print(f"âš ï¸ äº§å“ {product_id} ç¼ºå°‘è¯¦æƒ…URLï¼Œè·³è¿‡æŠ“å–")
                    enhanced_products.append(product)
                    continue
                
                # æŠ“å–è¯¦æƒ…æ•°æ®
                detail_data = self.fetch_product_detail(product_url, product_id)
                
                if detail_data:
                    # åˆå¹¶æ•°æ®
                    enhanced_product = self.merge_detail_into_product(product, detail_data)
                    enhanced_products.append(enhanced_product)
                else:
                    # æŠ“å–å¤±è´¥ï¼Œä½¿ç”¨åŸæ•°æ®
                    print(f"âš ï¸ äº§å“ {product_id} è¯¦æƒ…æŠ“å–å¤±è´¥ï¼Œä½¿ç”¨åŸæ•°æ®")
                    enhanced_products.append(product)
                    
            except Exception as e:
                print(f"âŒ å¤„ç†äº§å“ {product.get('productId', 'unknown')} æ—¶å‡ºé”™: {e}")
                enhanced_products.append(product)
        
        return enhanced_products
