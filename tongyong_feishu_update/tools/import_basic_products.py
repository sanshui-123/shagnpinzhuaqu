"""
å¯¼å…¥åŸºç¡€äº§å“ä¿¡æ¯åˆ°é£ä¹¦å·¥å…·
ä» scrape_category è¾“å‡ºä¸­æå–åŸºç¡€ä¿¡æ¯ï¼Œæ‰¹é‡åˆ›å»ºé£ä¹¦è®°å½•

âš ï¸ é‡è¦è¯´æ˜ï¼šå»é‡é€»è¾‘
- Stage1 å¯¼å…¥æ—¶ä½¿ç”¨ã€Œå•†å“é“¾æ¥ã€ï¼ˆURLï¼‰ä½œä¸ºå»é‡ä¾æ®
- å³ä½¿ productId ä¸åŒï¼Œåªè¦ URL ç›¸åŒå°±ä¼šè·³è¿‡
- å¯¼å…¥æ—¶ä¼šå°† URL ç¼–å·å†™å…¥ã€Œå•†å“IDã€å­—æ®µ
- Stage2 ä¼šæŠ“å–è¯¦æƒ…é¡µå¹¶å°†ã€Œå•†å“IDã€è¦†ç›–ä¸ºå“ç‰Œè´§å·
"""

import argparse
import json
import sys
from pathlib import Path

# æ·»åŠ çˆ¶ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from tongyong_feishu_update.clients import create_feishu_client


def normalize_url(url: str) -> str:
    """
    è§„èŒƒåŒ–URLï¼Œç”¨äºå»é‡æ¯”è¾ƒ

    å¤„ç†ï¼š
    - å»é™¤é¦–å°¾ç©ºæ ¼
    - ç»Ÿä¸€åè®®ä¸º https
    - å»é™¤æœ«å°¾æ–œæ 

    Args:
        url: åŸå§‹URL

    Returns:
        è§„èŒƒåŒ–åçš„URL
    """
    if not url:
        return ''
    cleaned = url.strip()
    cleaned = cleaned.replace('http://', 'https://')  # ç»Ÿä¸€åè®®
    return cleaned.rstrip('/')  # å»æ‰æœ«å°¾æ–œæ 


def import_basic_products(
    source_file: str,
    brand: str = "",
    batch_size: int = 30,
    verbose: bool = False
):
    """
    ä» scrape_category è¾“å‡ºå¯¼å…¥åŸºç¡€äº§å“ä¿¡æ¯åˆ°é£ä¹¦

    Args:
        source_file: scrape_category è¾“å‡ºæ–‡ä»¶è·¯å¾„
        brand: å“ç‰Œåç§°
        batch_size: æ‰¹é‡åˆ›å»ºçš„æ‰¹æ¬¡å¤§å°
        verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯

    Returns:
        dict: å¯¼å…¥ç»“æœç»Ÿè®¡
    """
    # 1. è¯»å–æºæ–‡ä»¶
    if verbose:
        print(f"ğŸ“„ æ­£åœ¨è¯»å–æºæ–‡ä»¶: {source_file}", file=sys.stderr)

    with open(source_file, 'r', encoding='utf-8') as f:
        data = json.load(f)

    # 2. æå–äº§å“åŸºç¡€ä¿¡æ¯
    products_to_import = []

    if 'results' in data and isinstance(data['results'], list):
        # scrape_category.js æ ¼å¼
        for result in data['results']:
            if 'products' in result and isinstance(result['products'], list):
                for item in result['products']:
                    product_id = item.get('productId', '')
                    if product_id:
                        products_to_import.append({
                            'product_id': product_id,
                            'url': item.get('url', ''),
                            'brand': brand or item.get('brand', '')
                        })

    if verbose:
        print(f"âœ… æå–åˆ° {len(products_to_import)} ä¸ªäº§å“", file=sys.stderr)

    if not products_to_import:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•äº§å“", file=sys.stderr)
        return {'success_count': 0, 'skip_count': 0, 'error_count': 0}

    # 3. è·å–é£ä¹¦ç°æœ‰è®°å½•
    if verbose:
        print("ğŸ” æ­£åœ¨è·å–é£ä¹¦ç°æœ‰è®°å½•...", file=sys.stderr)

    feishu_client = create_feishu_client()
    existing_records = feishu_client.get_records()

    if verbose:
        print(f"âœ… å·²è·å– {len(existing_records)} æ¡ç°æœ‰è®°å½•", file=sys.stderr)

    # 4. æ„å»ºå·²å­˜åœ¨çš„ URL é›†åˆï¼ˆç”¨äºå»é‡ï¼‰
    # âš ï¸ å»é‡é€»è¾‘å·²æ”¹ä¸ºåŸºäº URL è€Œé productId
    # ğŸ”¥ ä½¿ç”¨ normalize_url è§„èŒƒåŒ–ï¼Œé¿å…å› åè®®/æœ«å°¾æ–œæ ä¸åŒå¯¼è‡´é‡å¤
    existing_urls = set()
    for record_data in existing_records.values():
        fields = record_data.get('fields', {})
        url = fields.get('å•†å“é“¾æ¥', '')
        if url:
            existing_urls.add(normalize_url(url))

    if verbose:
        print(f"ğŸ“Š å·²æå– {len(existing_urls)} ä¸ªå·²å­˜åœ¨çš„å•†å“é“¾æ¥", file=sys.stderr)

    # 5. è¿‡æ»¤æ‰å·²å­˜åœ¨çš„è®°å½•ï¼ˆåŸºäº URL å»é‡ï¼‰
    # ğŸ”¥ ä½¿ç”¨ normalize_url è§„èŒƒåŒ–åè¿›è¡Œæ¯”è¾ƒ
    new_products = []
    skip_count = 0

    for product in products_to_import:
        url = product.get('url', '')
        normalized = normalize_url(url)
        if normalized in existing_urls:
            skip_count += 1
            if verbose:
                print(f"â­ï¸ è·³è¿‡å·²å­˜åœ¨çš„ URL: {url}", file=sys.stderr)
        else:
            new_products.append(product)

    if verbose:
        print(f"ğŸ“Š æ–°å¢: {len(new_products)} ä¸ªï¼Œè·³è¿‡: {skip_count} ä¸ª", file=sys.stderr)

    if not new_products:
        print("âœ… æ‰€æœ‰äº§å“ URL å·²å­˜åœ¨ï¼Œæ— éœ€åˆ›å»ºæ–°è®°å½•", file=sys.stderr)
        return {'success_count': 0, 'skip_count': skip_count, 'error_count': 0}

    # 6. æ‰¹é‡åˆ›å»ºæ–°è®°å½•
    create_records = []
    for product in new_products:
        create_records.append({
            'fields': {
                'å•†å“ID': product['product_id'],
                'å•†å“é“¾æ¥': product['url'],
                'å“ç‰Œå': product['brand']
            },
            'product_id': product['product_id']
        })

    if verbose:
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡åˆ›å»º {len(create_records)} æ¡è®°å½•...", file=sys.stderr)

    result = feishu_client.batch_create(create_records, batch_size=batch_size)

    success_count = result.get('success_count', 0)
    error_count = len(result.get('failed_batches', []))

    if verbose:
        print(f"âœ… åˆ›å»ºå®Œæˆ: æˆåŠŸ {success_count} æ¡ï¼Œå¤±è´¥ {error_count} ä¸ªæ‰¹æ¬¡", file=sys.stderr)

    return {
        'success_count': success_count,
        'skip_count': skip_count,
        'error_count': error_count
    }


def main():
    parser = argparse.ArgumentParser(
        description='å¯¼å…¥åŸºç¡€äº§å“ä¿¡æ¯åˆ°é£ä¹¦'
    )

    parser.add_argument(
        '--source',
        required=True,
        help='scrape_category è¾“å‡ºæ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--brand',
        default='',
        help='å“ç‰Œåç§°'
    )

    parser.add_argument(
        '--batch-size',
        type=int,
        default=30,
        help='æ‰¹é‡åˆ›å»ºçš„æ‰¹æ¬¡å¤§å°ï¼ˆé»˜è®¤ï¼š30ï¼‰'
    )

    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )

    args = parser.parse_args()

    try:
        result = import_basic_products(
            source_file=args.source,
            brand=args.brand,
            batch_size=args.batch_size,
            verbose=args.verbose
        )

        # è¾“å‡ºç»“æœæ‘˜è¦
        print(f"\nğŸ“Š å¯¼å…¥ç»“æœæ‘˜è¦:")
        print(f"  âœ… æ–°å¢è®°å½•: {result['success_count']}")
        print(f"  â­ï¸ è·³è¿‡è®°å½•: {result['skip_count']}")
        if result['error_count'] > 0:
            print(f"  âŒ å¤±è´¥æ‰¹æ¬¡: {result['error_count']}")

        sys.exit(0 if result['error_count'] == 0 else 1)

    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}", file=sys.stderr)
        if args.verbose:
            import traceback
            traceback.print_exc(file=sys.stderr)
        sys.exit(1)


if __name__ == '__main__':
    main()
