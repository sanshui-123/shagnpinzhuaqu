#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†ä½ çš„JSONæ ¼å¼è½¬æ¢ä¸ºfeishu_updateèƒ½è¯†åˆ«çš„æ ¼å¼
"""

import json
import sys
import os
import glob
from pathlib import Path
from datetime import datetime

def convert_single_json(input_file):
    """è½¬æ¢å•ä¸ªJSONæ–‡ä»¶ä¸ºfeishu_updateæ ¼å¼"""
    try:
        with open(input_file, 'r', encoding='utf-8') as f:
            data = json.load(f)

        # è½¬æ¢ä¸ºfeishu_updateèƒ½è¯†åˆ«çš„æ ¼å¼
        feishu_data = {
            "products": {
                data.get('å•†å“ID', ''): {
                    "productId": data.get('å•†å“ID', ''),
                    "productName": data.get('å•†å“æ ‡é¢˜', ''),
                    "detailUrl": data.get('å•†å“é“¾æ¥', ''),
                    "price": data.get('ä»·æ ¼', ''),
                    "brand": data.get('å“ç‰Œå', ''),
                    "category": "æœè£…",  # é»˜è®¤åˆ†ç±»
                    "gender": data.get('æ€§åˆ«', ''),
                    "description": data.get('è¯¦æƒ…é¡µæ–‡å­—', ''),

                    # é¢œè‰²å¤„ç†
                    "colors": data.get('é¢œè‰²', []) if isinstance(data.get('é¢œè‰²', []), list) else [],

                    # å°ºç å¤„ç†
                    "sizes": data.get('å°ºç ', []) if isinstance(data.get('å°ºç ', []), list) else [],

                    # å›¾ç‰‡å¤„ç†
                    "imageUrls": data.get('å›¾ç‰‡é“¾æ¥', []).split(', ') if isinstance(data.get('å›¾ç‰‡é“¾æ¥'), str) else data.get('å›¾ç‰‡é“¾æ¥', []) if data.get('å›¾ç‰‡é“¾æ¥') else [],

                    # å°ºç è¡¨
                    "sizeChart": data.get('å°ºç è¡¨', {}),

                    # å…¶ä»–ä¿¡æ¯
                    "scrapeInfo": {
                        "source": "single_url_fixed",
                        "timestamp": datetime.now().isoformat()
                    }
                }
            }
        }

        # ä¿å­˜è½¬æ¢åçš„æ–‡ä»¶
        output_file = input_file.replace('.json', '_feishu_format.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(feishu_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… è½¬æ¢å®Œæˆ: {input_file} â†’ {output_file}")
        print(f"   å•†å“ID: {data.get('å•†å“ID', 'N/A')}")
        print(f"   å•†å“åç§°: {data.get('å•†å“æ ‡é¢˜', 'N/A')}")
        print(f"   ä»·æ ¼: {data.get('ä»·æ ¼', 'N/A')}")

        return output_file

    except Exception as e:
        print(f"âŒ è½¬æ¢å¤±è´¥ {input_file}: {e}")
        return None

def convert_batch_json(input_dir):
    """æ‰¹é‡è½¬æ¢JSONæ–‡ä»¶"""
    pattern = os.path.join(input_dir, "single_url_fixed_*.json")
    json_files = glob.glob(pattern)

    if not json_files:
        print(f"âŒ åœ¨ {input_dir} ä¸­æœªæ‰¾åˆ°single_url_fixed_*.jsonæ–‡ä»¶")
        return

    print(f"âœ… æ‰¾åˆ° {len(json_files)} ä¸ªæ–‡ä»¶ï¼Œå¼€å§‹æ‰¹é‡è½¬æ¢...")

    converted_files = []
    failed_files = []

    for json_file in json_files:
        try:
            result = convert_single_json(json_file)
            if result:
                converted_files.append(result)
            else:
                failed_files.append(json_file)
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {json_file} - {e}")
            failed_files.append(json_file)

    # åˆ›å»ºæ‰¹é‡åˆå¹¶æ–‡ä»¶
    if converted_files:
        print(f"\nğŸ”„ åˆ›å»ºæ‰¹é‡åˆå¹¶æ–‡ä»¶...")

        all_products = {}
        for converted_file in converted_files:
            try:
                with open(converted_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # åˆå¹¶æ‰€æœ‰products
                all_products.update(data.get('products', {}))

            except Exception as e:
                print(f"âŒ è¯»å–è½¬æ¢æ–‡ä»¶å¤±è´¥: {converted_file} - {e}")

        # ä¿å­˜æ‰¹é‡æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        batch_file = f"batch_feishu_format_{timestamp}.json"

        with open(batch_file, 'w', encoding='utf-8') as f:
            json.dump({"products": all_products}, f, ensure_ascii=False, indent=2)

        print(f"âœ… æ‰¹é‡æ–‡ä»¶å·²åˆ›å»º: {batch_file}")
        print(f"   åŒ…å«äº§å“æ•°: {len(all_products)}")

    print(f"\nğŸ“Š è½¬æ¢æ±‡æ€»:")
    print(f"   æ€»æ–‡ä»¶æ•°: {len(json_files)}")
    print(f"   è½¬æ¢æˆåŠŸ: {len(converted_files)}")
    print(f"   è½¬æ¢å¤±è´¥: {len(failed_files)}")
    print(f"   æˆåŠŸç‡: {len(converted_files)/len(json_files)*100:.1f}%")

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='å°†JSONæ–‡ä»¶è½¬æ¢ä¸ºfeishu_updateæ ¼å¼')
    parser.add_argument('--input', '-i', type=str, help='å•ä¸ªJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--batch', '-b', action='store_true', help='æ‰¹é‡è½¬æ¢ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶')
    parser.add_argument('--dir', '-d', type=str, default='./scripts/multi_brand/brands/lecoqgolf/', help='æ‰¹é‡è½¬æ¢çš„ç›®å½•è·¯å¾„')

    args = parser.parse_args()

    if args.input:
        # è½¬æ¢å•ä¸ªæ–‡ä»¶
        print(f"ğŸ”„ è½¬æ¢å•ä¸ªæ–‡ä»¶: {args.input}")
        result = convert_single_json(args.input)
        if result:
            print(f"\nâœ… è½¬æ¢å®Œæˆï¼ç°åœ¨å¯ä»¥ä½¿ç”¨feishu_update:")
            print(f"python3 -m feishu_update.run_pipeline {result}")
        else:
            print("âŒ è½¬æ¢å¤±è´¥")
            sys.exit(1)

    elif args.batch:
        # æ‰¹é‡è½¬æ¢
        print(f"ğŸ”„ æ‰¹é‡è½¬æ¢ç›®å½•: {args.dir}")
        convert_batch_json(args.dir)

    else:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  # è½¬æ¢å•ä¸ªæ–‡ä»¶")
        print("  python3 convert_to_feishu_format.py --input single_url_fixed_xxx.json")
        print("")
        print("  # æ‰¹é‡è½¬æ¢")
        print("  python3 convert_to_feishu_format.py --batch --dir ./scripts/multi_brand/brands/lecoqgolf/")
        print("")
        print("  # è½¬æ¢åä½¿ç”¨feishu_update")
        print("  python3 -m feishu_update.run_pipeline batch_feishu_format_xxx.json")

if __name__ == "__main__":
    main()